#!/bin/bash
#
# Usage: <this script> [option]
# --heavy       : run node-sensity-heavy
# --lite        : run node-density-lite
# --nas         : use topo-aware-scheduler. Default uses default-scheduler
# --num-node n  : n is the number of worker nodes to participate in this test
# --num-pod n   : n is the number of pod per node
# --label tag   : texttual component of a run log file
# --dry-run     : skip invoking kube-burner
# --indexing    : default is true
#
# Exit code: 0, OK      - Clean up ns
#          : 1, NOT_OK  - No clean up so we can investigate further
#

export UUID=${UUID:-$(uuidgen)}
export ES_SERVER=https://search-perfscale-dev-chmf5l4sh66lvxbnadi4bznl3a.us-west-2.es.amazonaws.com:443
export LOG_LEVEL=${LOG_LEVEL:-info}
export CLEANUP_WHEN_FINISH=false
export INDEXING=${INDEXING:-true}
export GEN_CSV=true
export EMAIL_ID_FOR_RESULTS_SHEET="hnhan@redhat.com"
export SCHEDULER=${SCHEDULER:-default-scheduler}
export PODS_PER_NODE=${PODS_PER_NODE:-245}
export MAX_WAIT_TIMEOUT=1h
export POD_READY_THRESHOLD=100s
#export WORKER_NODE_LABEL=node-role.kubernetes.io/NAS
export QPS=1
export BURST=1

function num_workers () {
    WORKERS=$(oc get node | grep worker | awk '{print $1}')
    WORKER_LIST=( $WORKERS )
    NUM_NAS_WORKERS=${#WORKER_LIST[@]}
    echo $NUM_NAS_WORKERS
}

heavy=false
lite=false
lite_orig=false
cluster=false
label=""
dry_run=false
num_node=$(num_workers)
num_pod=245

function iter-workers () {
    WORKERS=$(oc get node | grep worker | awk '{print $1}')
    for w in $WORKERS; do
        export worker=$w
        cmd=$(echo $1 | envsubst)
        echo "--- $worker: $cmd"
        eval $cmd &>/dev/null
    done
}

function delete_hung_pods () {
    oc delete pods -A  -l kube-burner-job=node-density
}

function lite {
    # clear KB label left over from the last run. Else KB may use more nodes than $NODE_COUNT 
    iter-workers 'oc label --overwrite node ${worker} nas-node-density-'

    cmd="WORKLOAD=nas-node-density ./run.sh"
    echo $cmd
    if [ $dry_run == false ]; then
        eval $cmd
    fi
    echo results is on server $ES_SERVER with UUID $UUID index ripsaw-kube-burner
}

function lite-orig {
    # clear KB label left over from the last run. Else KB may use more nodes than $NODE_COUNT 
    iter-workers 'oc label --overwrite node ${worker} node-density-'

    cmd="WORKLOAD=node-density ./run.sh"
    echo $cmd
    if [ $dry_run == false ]; then
        eval $cmd
    fi
    echo results is on server $ES_SERVER with UUID $UUID index ripsaw-kube-burner

}

function heavy {
    # clear KB label left over from the last run. Else KB may use more nodes than $NODE_COUNT 
    iter-workers 'oc label --overwrite node ${worker} nas-node-density-'

    cmd="WORKLOAD=nas-node-density-heavy ./run.sh"
    echo $cmd
    if [ $dry_run == false ]; then
        eval $cmd
    fi
    echo results is on server $ES_SERVER with UUID $UUID index ripsaw-kube-burner
}

function cluster {
    # clear KB label left over from the last run. Else KB may use more nodes than $NODE_COUNT 
    iter-workers 'oc label --overwrite node ${worker} cluster-density'

    cmd="WORKLOAD=cluster-density ./run.sh"
    export JOB_ITERATIONS=10
    echo $cmd
    if [ $dry_run == false ]; then
        eval $cmd
    fi
    echo results is on server $ES_SERVER with UUID $UUID index ripsaw-kube-burner
}


function f_help () {
    me=`basename "$0"`
    echo Usage: $me [options]
    echo  "     --heavy            run node-density-heavy"
    echo  "     --lite             run node-density-lite"
    echo  "     --cluster          run cluster-density-lite"
    echo  "     --nas              topo-aware-scheduler. default is kube-scheduler"
    echo  "     --label <string>   used as a component of the log file name"
    echo  "     --num-node <num>   default is all worker nodes"
    echo  "     --num-pod  <num>   default is 254 pods per node"
    echo  "     --dry-run          skip"
    echo  "     --indexing         true/false"
}

longopts="label:,heavy,lite,lite-orig,cluster,nas,num-node:,num-pod:,dry-run,indexing:,help"
opts=$(getopt -q -o "" --longoptions "$longopts" -n "getopt.sh" -- "$@");
if [ $? -ne 0 ]; then
    echo "Unrecognized option specified"
    exit
fi

eval set -- "$opts";
while true; do
    case "$1" in
        --heavy)
            shift;
            heavy=true
            ;;
        --lite)
            shift;
            lite=true
            ;;
        --lite-orig)
            shift;
            lite_orig=true
            ;;
        --cluster)
            shift;
            cluster=true
            ;;
        --nas)
            shift;
            export SCHEDULER=topo-aware-scheduler
            ;;
        --num-node)
            shift;
            export NODE_COUNT=$1
            echo NODE_COUNT=$1
            num_node=$1
            shift;
            ;;
        --num-pod)
            shift;
            export PODS_PER_NODE=$1
            echo PODS_PER_NODE=$1
            num_pod=$1
            shift;
            ;;
        --label)
            shift;
            label=$1
            #echo label=$label
            shift;
            ;;
        --dry-run)
            shift;
            dry_run=true
            ;;
        --indexing)
            shift;
            export INDEXING=$1
            shift;
            ;;
        --)
            shift;
            break
            ;;
        --help)
            shift;
            f_help
            exit
            ;;

        *)
            echo "Invalid option: $1"
            exit
    esac
done

function dump_env () {
    echo "######"
    echo "heavy=$heavy"
    echo "lite=$lite"
    echo "cluster=$cluster"
    echo "SCHEDULER=$SCHEDULER"
    echo "NODE_COUNT=$NODE_COUNT"
    echo "PODS_PER_NODE=$PODS_PER_NODE"
    echo "INDEXING=$INDEXING"
    echo "######"
}

#
# extend uuid to improve grafana comparison
#
function ext_uuid () {
    if [  $SCHEDULER == topo-aware-scheduler ]; then
        UUID=ns${num_node}n${num_pod}p-${UUID}
    else
        UUID=ds${num_node}n${num_pod}p-${UUID}
    fi

    if [ $heavy == true ]; then
        UUID=h${UUID}
    elif [ $lite == true ]; then
        UUID=l${UUID}
    elif [ $cluster == true ]; then
        UUID=c${UUID}
    fi
}

if [ ${heavy} == true ]; then
    ext_uuid
    log_file=heavy-$label-$(date "+%Y-%m-%d-%T")-${UUID}.log
    echo log_file: $log_file
    dump_env 2>&1 | tee $log_file
    heavy 2>&1 | tee -a $log_file

elif [ ${lite} == true ]; then
    ext_uuid
    log_file=lite-$label-$(date "+%Y-%m-%d-%T")-${UUID}.log
    echo log_file: $log_file
    dump_env 2>&1 | tee $log_file
    lite 2>&1 | tee -a $log_file

elif [ ${lite_orig} == true ]; then
    ext_uuid
    log_file=lite-$label-$(date "+%Y-%m-%d-%T")-${UUID}.log
    echo log_file: $log_file
    dump_env 2>&1 | tee $log_file
    lite-orig 2>&1 | tee -a $log_file

elif [ ${cluster} == true ]; then
    ext_uuid
    log_file=cluster-$label-$(date "+%Y-%m-%d-%T")-${UUID}.log
    echo log_file: $log_file
    dump_env 2>&1 | tee $log_file
    cluster 2>&1 | tee -a $log_file

else
    echo f_help
    exit 1
fi

function dump_ns () {
    oc get pods -n $1
}

if [ -z $label ]; then
    echo f_help
    exit 1
fi

# if run failed, capture debug info
if [ -e $log_file ]; then
   if ( grep -q "Exiting" $log_file ) &&  ( grep -q 99th $log_file ) ; then
        echo "Normal exit"
        oc delete ns $UUID
    else
        echo "Error run"  | tee -a  $log_file
        echo "########### oc get pods -n $UUID:" | tee -a $log_file
        dump_ns $UUID 2>&1 | tee -a $log_file
        echo "###########" | tee -a $log_file
        mv $log_file $log_file-fail
        exit 1
    fi
fi

exit 0

# EOF
